Crea una nueva característica llamada price_class. Para precios mayores a $113 000, asigna price_class a 1. 
Para precios menores o iguales a $113 000, asigna 'price_class' a 0.

import pandas as pd

df = pd.read_csv('/datasets/train_data_us.csv')

# Creamos la nueva característica 'price_class' basada en la condición
df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

print(df.head())
*******************************************************************************************************************
Muchas librerías de machine learning requieren que las características se almacenen en variables separadas. 
Declara dos variables: features para características / target para objetivo

import pandas as pd

df = pd.read_csv('/datasets/train_data_us.csv')

df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

print(features.shape)
print(target.shape)
********************************************************************************************************************
Comencemos con el entrenamiento del modelo. En la Lección 5 guardamos el conjunto de datos de entrenamiento en 
las variables features y target. Para iniciar el entrenamiento, llama al método fit() y pásale tus variables 
como argumento.

import pandas as pd
from sklearn import set_config

# no cambies estos parámetros de configuración
set_config(print_changed_only=False)

# importa el árbol de decisión de la librería sklearn
from sklearn.tree import DecisionTreeClassifier 
# < escribe tu código aquí >
model = DecisionTreeClassifier() 

df = pd.read_csv('/datasets/train_data_us.csv')

df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

# crea un modelo vacío y asígnalo a una variable
# entrena un modelo llamando al método fit()
# < escribe tu código aquí >
model.fit(features, target) 

print(model)
************************************************************************************************************************
Ahora tenemos un modelo entrenado en la variable model . Para predecir respuestas, llama al método predict() 
y pásale la tabla con las características de las nuevas observaciones.

import pandas as pd
from sklearn.tree import DecisionTreeClassifier

df = pd.read_csv('/datasets/train_data_us.csv')

df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

model = DecisionTreeClassifier()

model.fit(features, target)

new_features = pd.DataFrame(
    [
        [None, None, 2.8, 25, None, 25, 0, 0, 0, None, 0, 30706.0, 7877.0],
        [None, None, 2.75, 25, None, 25, 0, 0, 0, None, 0, 36421.0, 9176.0]
    ],
    columns=features.columns
)

# completa la tabla con las nuevas características
new_features.loc[0, 'total_area'] = 900.0
# < escribe tu código aquí > 

# predice respuestas y muestra el resultado en la pantalla
# < escribe tu código aquí >
# Completa las características del primer apartamento
new_features.loc[0, 'total_area'] = 900.0
new_features.loc[0, 'bedrooms'] = 12
new_features.loc[0, 'living_area'] = 409.7
new_features.loc[0, 'kitchen_area'] = 112.0

# Completa las características del segundo apartamento
new_features.loc[1, 'total_area'] = 109.0
new_features.loc[1, 'bedrooms'] = 2
new_features.loc[1, 'living_area'] = 32.0
new_features.loc[1, 'kitchen_area'] = 40.5

answers = model.predict(new_features)
print(answers)
***************************************************************************************************************************
Asigna las 3 primeras observaciones del nuevo conjunto de datos a la variable `test_df`. Guarda las funciones utilizadas
para la clasificacion en la variable `test_features`. Haz una prediccion de las respuestas.

import pandas as pd
from sklearn.tree import DecisionTreeClassifier

df = pd.read_csv('/datasets/train_data_us.csv')

df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

model = DecisionTreeClassifier(random_state=12345)

model.fit(features, target)

test_df = pd.read_csv('/datasets/test_data_us.csv')[:3]

test_df.loc[test_df['last_price'] > 113000, 'price_class'] = 1
test_df.loc[test_df['last_price'] <= 113000, 'price_class'] = 0

test_features = test_df.drop(['last_price', 'price_class'], axis=1)
test_target = test_df['price_class']
test_predictions = model.predict(test_features)

print('Predicciones:', test_predictions)
print('Respuestas correctas:', test_target.values)
********************************************************************************************************************************
Tres ejemplos no son suficientes para saber si el modelo funciona bien o no. Cuenta el número de errores para todo el 
conjunto de prueba. Escribe la función error_count().

import pandas as pd
from sklearn.tree import DecisionTreeClassifier

df = pd.read_csv('/datasets/train_data_us.csv')

df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

model = DecisionTreeClassifier(random_state=12345)

model.fit(features, target)

test_df = pd.read_csv('/datasets/test_data_us.csv')

test_df.loc[test_df['last_price'] > 113000, 'price_class'] = 1
test_df.loc[test_df['last_price'] <= 113000, 'price_class'] = 0

test_features = test_df.drop(['last_price', 'price_class'], axis=1)
test_target = test_df['price_class']
test_predictions = model.predict(test_features)

def error_count(answers, predictions):
    # Inicializa el contador de errores
    error_counter = 0
    
    # Compara las respuestas y predicciones para contar los errores
    for i in range(len(answers)):
        if answers[i] != predictions[i]:
            error_counter += 1
    
    return error_counter

print('Errores:', error_count(test_target, test_predictions))
***********************************************************************************************************************************
Usando la funcion `accuracy()`, esta divide el numero de respuestas correctas entre el numero total de predicciones 
y devuelve la puntuacion

import pandas as pd
from sklearn.tree import DecisionTreeClassifier

df = pd.read_csv('/datasets/train_data_us.csv')

df.loc[df['last_price'] > 263000, 'price_class'] = 1
df.loc[df['last_price'] <= 263000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

model = DecisionTreeClassifier(random_state=12345)

model.fit(features, target)

test_df = pd.read_csv('/datasets/test_data_us.csv')

test_df.loc[test_df['last_price'] > 263000, 'price_class'] = 1
test_df.loc[test_df['last_price'] <= 263000, 'price_class'] = 0

test_features = test_df.drop(['last_price', 'price_class'], axis=1)
test_target = test_df['price_class']
test_predictions = model.predict(test_features)

def accuracy(answers, predictions):
    # Inicializa el contador de respuestas correctas
    correct = 0
    
    # Compara las respuestas y predicciones para contar las respuestas correctas
    for i in range(len(answers)):
        if answers[i] == predictions[i]:
            correct += 1
    
    # Calcula la exactitud dividiendo las respuestas correctas por el número total de predicciones
    accuracy_score = correct / len(answers)
    
    return accuracy_score

# Calcula la exactitud y muestra el resultado en pantalla
accuracy_score = accuracy(test_target, test_predictions)
print('Exactitud:', accuracy_score)

*****************************************************************************************************************************************
¿La puntuación de exactitud difiere entre el conjunto de entrenamiento y el conjunto de prueba? Calcula los valores

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

df = pd.read_csv('/datasets/train_data_us.csv')

df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

model = DecisionTreeClassifier(random_state=12345)

model.fit(features, target)

test_df = pd.read_csv('/datasets/test_data_us.csv')

test_df.loc[test_df['last_price'] > 113000, 'price_class'] = 1
test_df.loc[test_df['last_price'] <= 113000, 'price_class'] = 0

test_features = test_df.drop(['last_price', 'price_class'], axis=1)
test_target = test_df['price_class']

train_predictions = model.predict(features)
test_predictions = model.predict(test_features)  # Cálculo de predicciones para el conjunto de prueba

train_accuracy = accuracy_score(target, train_predictions)  # Cálculo de la precisión para el conjunto de entrenamiento
test_accuracy = accuracy_score(test_target, test_predictions)  # Cálculo de la precisión para el conjunto de prueba

print('Exactitud')
print('Training set:', train_accuracy)  # Mostrar precisión del conjunto de entrenamiento
print('Test set:', test_accuracy)  # Mostrar precisión del conjunto de prueba

*********************************************************************************************************************************************
Enséñale al modelo a probar con diferentes valores de un parámetro: max_depth.

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

df = pd.read_csv('/datasets/train_data.csv')

df.loc[df['last_price'] > 5650000, 'price_class'] = 1
df.loc[df['last_price'] <= 5650000, 'price_class'] = 0

features = df.drop(['last_price', 'price_class'], axis=1)
target = df['price_class']

best_model = None
best_result = 0

for depth in range(1, 6):
    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)  # Usa 'depth' como el parámetro max_depth
    model.fit(features, target)  # Entrena el modelo
    predictions = model.predict(features)  # Obtiene las predicciones del modelo
    result = accuracy_score(target, predictions)  # Calcula la exactitud

    if result > best_result:
        best_model = model
        best_result = result

print("Exactitud del mejor modelo en el conjunto de entrenamiento:", best_result)
*********************************************************************************************************************************************
Separa el dataset en dos conjuntos:

import pandas as pd
from sklearn.model_selection import train_test_split

df = pd.read_csv('/datasets/train_data_us.csv')
df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)

features_train = df_train.drop(['last_price', 'price_class'], axis=1)
target_train = df_train['price_class']

features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)
target_valid = df_valid['price_class']

print(features_train.shape)
print(target_train.shape)
print(features_valid.shape)
print(target_valid.shape)
*********************************************************************************************************************************************
Cambia el hiperparámetro max_depthen el bucle de 1 a 5. Por cada valor, imprime la calidad para el conjunto de validación.

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

df = pd.read_csv('/datasets/train_data_us.csv')
df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)

features_train = df_train.drop(['last_price', 'price_class'], axis=1)
target_train = df_train['price_class']
features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)
target_valid = df_valid['price_class']

for depth in range(1, 6):
    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)  # Crea el modelo con max_depth = depth
    model.fit(features_train, target_train)  # Entrena el modelo

    predictions_valid = model.predict(features_valid)  # Realiza predicciones con el conjunto de validación
    accuracy = accuracy_score(target_valid, predictions_valid)  # Calcula la precisión del modelo

    print("max_depth =", depth, ":", accuracy)
*********************************************************************************************************************************************
Completa el precódigo para hacer un bucle que pruebe modelos de bosque aleatorio con varios números de estimadores (árboles).

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

df = pd.read_csv('/datasets/train_data_us.csv')

df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

df_train, df_valid = train_test_split(df, test_size=0.25, random_state=54321)  # 25 % para el conjunto de validación

features_train = df_train.drop(['last_price', 'price_class'], axis=1)
target_train = df_train['price_class']
features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)
target_valid = df_valid['price_class']

best_score = 0
best_est = 0

for est in range(1, 11):  # Prueba con 10 estimadores
    model = RandomForestClassifier(random_state=54321, n_estimators=est)  # Configura el número de estimadores
    model.fit(features_train, target_train)  # Entrena el modelo en el conjunto de entrenamiento
    score = model.score(features_valid, target_valid)  # Calcula la precisión en el conjunto de validación

    if score > best_score:
        best_score = score
        best_est = est

    print("Accuracy con {} estimadores: {}".format(est, score))

print("Mejor accuracy en el conjunto de validación (n_estimators = {}): {}".format(best_est, best_score))

final_model = RandomForestClassifier(random_state=54321, n_estimators=best_est)  # Utiliza el mejor número de estimadores
final_model.fit(features_train, target_train)
*********************************************************************************************************************************************
Entrena un modelo de regresión logística en el conjunto de entrenamiento, luego calcula el valor de accuracy tanto en el conjunto de 
entrenamiento como en el conjunto de validación.

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

df = pd.read_csv('/datasets/train_data_us.csv')

df.loc[df['last_price'] > 113000, 'price_class'] = 1
df.loc[df['last_price'] <= 113000, 'price_class'] = 0

df_train, df_valid = train_test_split(df, test_size=0.25, random_state=54321)  # 25 % para el conjunto de validación

features_train = df_train.drop(['last_price', 'price_class'], axis=1)
target_train = df_train['price_class']
features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)
target_valid = df_valid['price_class']

model = LogisticRegression(random_state=54321, solver='liblinear')  # Inicializa el constructor de regresión logística
model.fit(features_train, target_train)  # Entrena el modelo en el conjunto de entrenamiento

score_train = model.score(features_train, target_train)  # Calcula la precisión en el conjunto de entrenamiento
score_valid = model.score(features_valid, target_valid)  # Calcula la precisión en el conjunto de validación

print("Accuracy del modelo de regresión logística en el conjunto de entrenamiento:", score_train)
print("Accuracy del modelo de regresión logística en el conjunto de validación:", score_valid)
*********************************************************************************************************************************************
Escribe una función mse(). Debe tomar respuestas correctas y predicciones y devolver el valor del error cuadrático medio.

def mse(answers, predictions):
    total = 0
    for i in range(len(answers)):
        total += (predictions[i] - answers[i]) ** 2  # Agrega el error cuadrático de cada observación

    result = total / len(answers)  # Divide la suma entre el número de observaciones
    return result

answers = [623, 253, 150, 237]
predictions = [649, 253, 370, 148]

print(mse(answers, predictions))
*********************************************************************************************************************************************
También hay una función para calcular el EMC en sklearn.

from sklearn.metrics import mean_squared_error  # Importa la función mean_squared_error desde sklearn.metrics

answers = [623, 253, 150, 237]
predictions = [649, 253, 370, 148]

result = mean_squared_error(answers, predictions)  # Llama a la función mean_squared_error
print(result)
*********************************************************************************************************************************************
Prepara los datos y encuentra el precio promedio.

import pandas as pd

df = pd.read_csv('/datasets/train_data_us.csv')

# Crear las variables features y target
features = df.drop(['last_price'], axis=1)
target = df['last_price']

# Calcular el valor promedio de la variable target
average_price = target.mean()

# Imprimir el resultado
print("Average price:", average_price)
*********************************************************************************************************************************************
Calcula el ECM para el conjunto de entrenamiento usando el precio promedio como valor de predicción.

import pandas as pd
from sklearn.metrics import mean_squared_error

df = pd.read_csv('/datasets/train_data_us.csv')

features = df.drop(['last_price'], axis=1)
target = df['last_price'] / 100000

# Calcular la media del target para usarla como predicción
prediction = pd.Series(target.mean(), index=target.index)

# Calcular el Error Cuadrático Medio (ECM)
mse = mean_squared_error(target, prediction)

print('MSE:', mse)
*********************************************************************************************************************************************
No necesitamos "dólares cuadrados". Para obtener dólares normales encuentra la RECM sacando la raíz cuadrada del ECM.

import pandas as pd
from sklearn.metrics import mean_squared_error

df = pd.read_csv('/datasets/train_data_us.csv')

features = df.drop(['last_price'], axis=1)
target = df['last_price'] / 100000

predictions = pd.Series(target.mean(), index=target.index)
mse = mean_squared_error(target, predictions)

# Calcular la raíz cuadrada del Error Cuadrático Medio (ECM) para obtener el RMSE
rmse = mse ** 0.5

print('RMSE:', rmse)
*********************************************************************************************************************************************
1.- Destina 25 % de los datos al conjunto de validación y el resto para el de entrenamiento.
2.- Entrena modelos de árbol de decisión para un problema de regresión con diferentes valores de profundidad entre 1 y 6.
3.- Calcula el valor de RECM en el conjunto de validación para cada modelo.
4.- Almacena en la variable best_modelel modelo con el mejor valor de RECM en el conjunto de validación.

import pandas as pd
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

df = pd.read_csv('/datasets/train_data_us.csv')

features = df.drop(['last_price'], axis=1)
target = df['last_price'] / 1000000

features_train, features_valid, target_train, target_valid = train_test_split(
    features, target, test_size=0.25, random_state=12345)  # Segmenta el 25 % de los datos para el conjunto de validación

best_model = None
best_result = 10000
best_depth = 0

for depth in range(1, 7):  # Selecciona el rango del hiperparámetro para la profundidad
    model = DecisionTreeRegressor(max_depth=depth, random_state=12345)  # Inicializa el modelo
    model.fit(features_train, target_train)  # Entrena el modelo en el conjunto de entrenamiento
    predictions_valid = model.predict(features_valid)  # Predice en el conjunto de validación
    result = mean_squared_error(target_valid, predictions_valid) ** 0.5  # Calcula el RMSE en el conjunto de validación

    if result < best_result:
        best_model = model
        best_result = result
        best_depth = depth

print(f"RMSE del mejor modelo en el conjunto de validación (max_depth = {best_depth}): {best_result}")
*********************************************************************************************************************************************
1.- Extrae las características para entrenamiento en features y divide la característica objetivo last_price entre 1000000, luego guárdala en la variable target.
2.- Selecciona 25 % de los datos para la muestra de validación (prueba), lo demás será para el entrenamiento.
3.- Entrena modelos de bosque aleatorio para el problema de regresión:
con el número de árboles: de 10 a 50, en intervalos de 10,
con una profundidad máxima de 1 a 10.
4.- Calcula RECM en el conjunto de validación para cada modelo.
5.- Almacena en la variable best_model el modelo con el mejor valor de RECM en el conjunto de validación.

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

df = pd.read_csv('/datasets/train_data_us.csv')

# Aísla las características excepto 'last_price'
features = df.drop(['last_price'], axis=1)
# Aísla la característica objetivo y divide entre 1000000
target = df['last_price'] / 1000000

# Selecciona 25 % de los datos para el conjunto de validación (test)
features_train, features_valid, target_train, target_valid = train_test_split(
    features, target, test_size=0.25, random_state=12345)

best_model = None
best_result = 10000
best_est = 0
best_depth = 0

for est in range(10, 51, 10):
    for depth in range(1, 11):
        model = RandomForestRegressor(random_state=12345, n_estimators=est, max_depth=depth)
        model.fit(features_train, target_train)
        predictions_valid = model.predict(features_valid)
        result = mean_squared_error(target_valid, predictions_valid) ** 0.5

        if result < best_result:
            best_model = model
            best_result = result
            best_est = est
            best_depth = depth

print(f"RMSE del mejor modelo en el conjunto de validación: {best_result} con n_estimators: {best_est} y max_depth: {best_depth}")
*********************************************************************************************************************************************
- Lleva las características de entrenamiento a la variable features y la característica last_price del objetivo a la variable target. 
- Divide el valor de la característica target entre 1000000.
- Inicializa un modelo de regresión lineal y entrénalo. Calcula el valor de la métrica RECM en el conjunto de validación y almacénalo 
en la variable result.

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

df = pd.read_csv('/datasets/train_data_us.csv')

# Extrae las características excepto 'last_price'
features = df.drop(['last_price'], axis=1)
# Extrae 'last_price' y divide entre 1000000
target = df['last_price'] / 1000000

# Divide los datos en conjuntos de entrenamiento y validación (75% entrenamiento, 25% validación)
features_train, features_valid, target_train, target_valid = train_test_split(
    features, target, test_size=0.25, random_state=12345)

# Inicializa el modelo de regresión lineal
model = LinearRegression()

# Entrena el modelo en el conjunto de entrenamiento
model.fit(features_train, target_train)

# Obtiene las predicciones del modelo en el conjunto de validación
predictions_valid = model.predict(features_valid)

# Calcula el RMSE en el conjunto de validación
result = mean_squared_error(target_valid, predictions_valid) ** 0.5

print("RMSE del modelo de regresión lineal en el conjunto de validación:", result)
*********************************************************************************************************************************************
Para aprobar el ejercicio, entrena el mejor modelo con hiperparámetros óptimos en todo el dataset. Si no tienes la seguridad de
cuál es el mejor, tómate la libertad de intentarlo con los tres.
 
import pandas as pd
from sklearn.ensemble import RandomForestRegressor

df = pd.read_csv('/datasets/train_data_us.csv')

# Inicializa las variables
features = df.drop(['last_price'], axis=1)
target = df['last_price'] / 100000

# Inicializa el constructor para el modelo RandomForestRegressor con los hiperparámetros óptimos
final_model = RandomForestRegressor(n_estimators=40, random_state=12345)

# Entrena el modelo en el conjunto de datos completo
final_model.fit(features, target)
*********************************************************************************************************************************************
 